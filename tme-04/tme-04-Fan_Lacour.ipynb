{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IA & Data science (LU3IN0226) -- 2022-2023\n",
    "--------\n",
    "*&copy; Equipe pédagogique: Christophe Marsala, Olivier Schwander, Jean-Noël Vittaut.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"RED\">**[Q]**</font> **Indiquer dans la boîte ci-dessous vos noms et prénoms :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Céline Fan & Mélissa Lacour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Renommer ce fichier ipython**\n",
    "\n",
    "Tout en haut de cette page, cliquer sur <tt>tme-04</tt> et rajouter à la suite de <tt>tme-04</tt> les noms des membres du binômes séparés par un tiret.\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">IMPORTANT: soumission de votre fichier final</font>\n",
    "\n",
    "**Nom à donner au fichier à poster** : *tme-04-Nom1_Nom2.ipynb* \n",
    "- *Nom1* et *Nom2* : noms des membres du binôme\n",
    "- ne pas compresser ou faire une archive: il faut rendre le fichier ipython tel quel, éventuellement, si vous avez d'autres fichiers vous les rendez séparément.\n",
    "\n",
    "**Echancier pour la soumission de votre compte-rendu:**\n",
    "- le compte-rendu d'une séance doit être remis obligatoirement <font color=\"RED\">avant la séance suivante</font>.\n",
    "\n",
    "**Le compte-rendu est soumis sur la page Moodle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'desc_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6164/2810857985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdesc_set\u001b[0m\u001b[0;31m# Importation de librairies standards:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'desc_set' is not defined"
     ]
    }
   ],
   "source": [
    "desc_set# Importation de librairies standards:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "# un nouvel import utile pour la 3D:\n",
    "from matplotlib import cm\n",
    "\n",
    "# Les instructions suivantes sont TRES utiles pour recharger automatiquement \n",
    "# le code modifié dans les librairies externes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'une librairie\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Afin de pouvoir réutiliser les classes et fonctions écrites précédemment dans les séances de TDTME, vous allez construire une librairie avec vos fonctions.\n",
    "\n",
    "Cette librairie, qui s'appellera IADS, contiendra toutes les classes et fonctions que vous allez développer lors de vos séances de TDTME. Elle sera construite donc séance après séance par l'ajout des nouvelles classes et fonctions que vous écrirez.\n",
    "\n",
    "<font color=\"RED\">Important:</font> dans un premier temps, vous devez écrire les classes et fonctions demandées dans le notebook de la séance de TDTME courante. A la séance suivante, ou une fois que tout fonctionne correctement, vous rajouterez les classes et fonctions écrites et testées dans vos fichiers de la librairie IADS pour pouvoir réutiliser vos classifieurs par la suite dans les séances suivantes.\n",
    "\n",
    "Récupérer et désarchiver l'archive iads.tgz de telle sorte que le répertoire `iads` soit un répertoire frère du répertoire `tme04`.\n",
    "\n",
    "Ainsi, vous devrez avoir une arborescence qui ressemble à ça:\n",
    "\n",
    "    - LU3IN026/\n",
    "        - tme-01/\n",
    "            - tme-01.ipynb\n",
    "        - tme-02/\n",
    "            - tme-02.ipynb\n",
    "        - tme-03/\n",
    "            - tme-03.ipynb\n",
    "        - tme-04/\n",
    "            - tme-04.ipynb\n",
    "        - iads/\n",
    "            - Classifiers.py\n",
    "            - utils.py\n",
    "            - evaluation.py\n",
    "            - __init__.py\n",
    "          \n",
    "\n",
    "<b>Important</b> :\n",
    "- ce fichier tme-04.ipynb doit toujours rester dans le répertoire tme-04/\n",
    "- pour ouvrir les fichiers python (extension .py) qui se trouvent dans le répertoire iads/ il est nécessaire d'utiliser un éditeur de texte comme emacs, gedit, idle,...\n",
    "</div>\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Ouvrir et compléter les fichiers Classifiers.py et utils.py**\n",
    "\n",
    "Pour compléter ces fichiers, reprendre le code écrit dans les TDTME précédents.\n",
    "- dans `utils.py`: `genere_dataset_uniform`, `genere_dataset_gaussian`, `plot2DSet`, `plot_frontiere` et `create_XOR`\n",
    "- dans `Classifiers.py`: reprendre le code des classifiers que vous avez déjà définis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Mise à jour de la librairie `iads`**\n",
    "\n",
    "En premier lieu, vérifier que votre librairie `iads` est bien à jour : elle doit maintenant contenir toutes les fonctions et classes que mises au point et testées dans les séances précédentes. Une fois à jour, importer la librairie pour pouvoir l'utiliser dans ce notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de votre librairie iads:\n",
    "# La ligne suivante permet de préciser le chemin d'accès à la librairie iads\n",
    "import sys\n",
    "sys.path.append('../')   # iads doit être dans le répertoire père du répertoire courant !\n",
    "\n",
    "# Importation de la librairie iads\n",
    "import iads as iads\n",
    "\n",
    "# importation de Classifiers\n",
    "from iads import Classifiers as classif\n",
    "\n",
    "# importation de utils\n",
    "from iads import utils as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Attention:</b> à partir d'ici, lorsque vous voulez utiliser un algorithme qui se trouve dans le fichier `Classifier.py` il est nécessaire de préfixer son nom par `classif.` et pour utiliser une fonction du fichier `utils.py`, il faut préfixer le nom de la fonction par `ut.`\n",
    "\n",
    "\n",
    "Dans les boîtes qui vont suivre, on appliquera ce principe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMARQUE: une fois les importations faites, les fonctions de utils sont utilisables\n",
    "#  en mettant ut. devant leur nom:\n",
    "\n",
    "# Exemple d'utilisation:\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "d_desc_gauss, d_lab_gauss = ut.genere_dataset_gaussian(np.array([1,1]) ,np.array([[1,0],[0,1]]), \\\n",
    "                                                       np.array([-0.5,-1]), np.array([[1,0],[0,1]]), \\\n",
    "                                                       100)\n",
    "\n",
    "print(\"Taille du dataset généré :\", np.shape(d_desc_gauss), \"exemples\")\n",
    "\n",
    "# Affichage :\n",
    "ut.plot2DSet(d_desc_gauss,d_lab_gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = d_desc_gauss\n",
    "label = d_lab_gauss\n",
    "\n",
    "# Réinitialisation de la graine pour la mise au point (à enlever ensuite !)\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# De même, les classes de Classifiers sont utilisables en mettant classif. devant leur nom:\n",
    "# Création d'un perceptron\n",
    "perceptron1 = classif.ClassifierPerceptron(2, learning_rate=0.01, init=True)\n",
    "\n",
    "perceptron1.train(data, label)\n",
    "print(\"Accuracy : \", perceptron1.accuracy(data,label))\n",
    "\n",
    "# Affichage de la frontière de séparation des classes\n",
    "ut.plot_frontiere(data,label,perceptron1,step=60)\n",
    "ut.plot2DSet(data,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà, à partir de maintenant, vous pourrez donc ainsi réutiliser dans vos notebooks des classes et des fonctions écrites précédemment sans avoir à recopier tout le code implémenté !\n",
    "\n",
    "Dans les prochains notebooks, vous mettrez au point les fonctions et classes demandées et une fois qu'elles seront au point et validées, vous pourrez les transférer dans votre librairie IADS pour pouvoir les réutiliser dans les séances suivantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Pour étudier la convergence du perceptron, on a besoin de garder une trace de tous les poids $w$ qui ont été utilisés. Pour cela, rajouter à la classe `ClassifierPerceptron` un attribut de nom `allw` qui est initialisé aux poids initiaux dans `__init__` par:\n",
    "\n",
    "    self.allw =[self.w.copy()] # stockage des premiers poids\n",
    "        \n",
    "cet attribut est à mettre jour pendant l'entraînement `train_step` du perceptron, après le changement de valeur des poids. \n",
    "\n",
    "<b>Remarque</b>: attention ! pour copier le vecteur $w$ penser à faire une copie profonde...\n",
    "\n",
    "\n",
    "Ajouter aussi dans la classe un accesseur `get_allw()` pour récupérer la valeur de `allw`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utiliser une fois la classe ClassifierPerceptron modifiée par l'ajout de allw\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = 2\n",
    "eps = 5e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "# Réinitialisation de la graine pour la mise au point (à enlever ensuite !)\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "perceptron2 = classif.ClassifierPerceptron(dim, learning_rate=eps, init=poids_0)\n",
    "\n",
    "les_differences = perceptron2.train(data, label,nb_max=100)\n",
    "\n",
    "# récupération de l'évolution des w au cours de l'apprentissage \n",
    "# perceptron initialisé à 0\n",
    "# si allw est sous forme de liste de couples [w1, w2], on doit la convertir en np.array pour la suite:\n",
    "allw = np.array(perceptron2.get_allw()) \n",
    "\n",
    "# Tracé de l'évolution des w:\n",
    "plt.figure()\n",
    "plt.plot(allw[:,0]) # première coordonnée du vecteur poids: w1\n",
    "plt.plot(allw[:,1]) # deuxième coordonnée du vecteur poids: w2\n",
    "plt.title('Evolution des w au cours des itérations du perceptron')\n",
    "plt.xlabel('iterations')\n",
    "plt.legend(['w1','w2'])\n",
    "\n",
    "# Sauvegarde de la figure obtenue (décommenter la ligne ci-dessous):\n",
    "#plt.savefig('out/cvg.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compléments sur le perceptron\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Afin d'améliorer notre classifieur perceptron, nous allons considérer une version modifiée de la classe `ClassifierPerceptronBiais`, que nous appellerons `ClassifierPerceptronBiais` pour construire un perceptron en utilisant un <b>biais</b> qui facilite la convergence du modèle: pour déterminer si une mise à jour des poids doit être faite, le critère de mauvaise classification est remplacé par\n",
    "$$ f(\\mathbf x_i) y_i < 1 $$\n",
    "où $f(\\mathbf x_i)$ est le score obtenu pour $x_i$.\n",
    "\n",
    "<b>Idée</b>: on veut que $f(\\mathbf x_i)$ et $y_i$ soient du même signe ET que $f(\\mathbf x_i)$ soit suffisamment grand (en valeur absolue).\n",
    "    \n",
    "C'est une version dite *stabilisée* du perceptron où les points ne sont considérés bien classés que lorsque $f(\\mathbf x_i) y_i \\geq 1$. Dans le cas contraire, on met à jour les poids.\n",
    "\n",
    "La mise à jour des poids tient alors compte de ce biais: $$ w = w +\\epsilon (y_i- f(\\mathbf x_i))x_i.$$\n",
    "\n",
    "</div>    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> Ecrire la classe `ClassifierPerceptronBiais` (tout d'abord dans une boîte de ce notebook, puis vous la copierez dans votre fichier `Classifiers.py`) et tester le code suivant qui doit être fonctionnel. \n",
    "\n",
    "Pour éviter d'avoir à récrire les fonctions déjà écrites pour le perceptron et qui ne changeront pas dans le cas du perceptron avec biais, on fait hériter la classe `ClassifierPerceptronBiais` de la classe `ClassifierPerceptron`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ A COMPLETER :\n",
    "\n",
    "# Remarque : quand vous transférerez cette classe dans le fichier classifieur.py \n",
    "# de votre librairie, il faudra enlever \"classif.\" en préfixe de la classe ClassifierPerceptron:\n",
    "\n",
    "class ClassifierPerceptronBiais(classif.ClassifierPerceptron):\n",
    "    \"\"\" Perceptron de Rosenblatt avec biais\n",
    "        Variante du perceptron de base\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dimension, learning_rate=0.01, init=True):\n",
    "        \"\"\" Constructeur de Classifier\n",
    "            Argument:\n",
    "                - input_dimension (int) : dimension de la description des exemples (>0)\n",
    "                - learning_rate (par défaut 0.01): epsilon\n",
    "                - init est le mode d'initialisation de w: \n",
    "                    - si True (par défaut): initialisation à 0 de w,\n",
    "                    - si False : initialisation par tirage aléatoire de valeurs petites\n",
    "        \"\"\"\n",
    "        # Appel du constructeur de la classe mère\n",
    "        super().__init__(input_dimension, learning_rate, init)\n",
    "        # Affichage pour information (décommentez pour la mise au point)\n",
    "        #print(\"Init perceptron biais: w= \",self.w,\" learning rate= \",learning_rate)\n",
    "        \n",
    "    def train_step(self, desc_set, label_set):\n",
    "        \"\"\" Réalise une unique itération sur tous les exemples du dataset\n",
    "            donné en prenant les exemples aléatoirement.\n",
    "            Arguments:\n",
    "                - desc_set: ndarray avec des descriptions\n",
    "                - label_set: ndarray avec les labels correspondants\n",
    "        \"\"\"        \n",
    "        desc_copie = desc_set.copy()\n",
    "        np.random.shuffle(desc_copie)\n",
    "        \n",
    "        for i in range(len(desc_copie)):\n",
    "            p = self.score(desc_copie[i])\n",
    "            indice_xi = np.where(np.all(desc_set == desc_copie[i], axis=1))[0][0]\n",
    "            yi = label_set[indice_xi]\n",
    "            \n",
    "            if(p*yi < 1):\n",
    "                self.w = self.w + self.learning_rate * (yi - p) * desc_copie[i]\n",
    "                self.allw.append(self.w.copy())\n",
    "        return\n",
    "        \n",
    "# ------------------------ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = 2\n",
    "eps = 5e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "# Création et entraînement du perceptron sur les données générées\n",
    "\n",
    "# -------------------------------\n",
    "#### ATTENTION : commenter la ligne qui correspond à votre cas :\n",
    "\n",
    "## La classe ClassifierPerceptronBiais a été mise dans Classifier.py :\n",
    "#perc = classif.ClassifierPerceptronBiais(dim, eps)\n",
    "\n",
    "## La classe ClassifierPerceptronBiais se trouve dans ce notebook :\n",
    "perceptron_biais = ClassifierPerceptronBiais(dim, learning_rate=eps, init=poids_0)\n",
    "# -------------------------------\n",
    "\n",
    "les_differences = perceptron_biais.train(data, label)\n",
    "\n",
    "# récupération de l'évolution des w au cours de l'apprentissage \n",
    "# perceptron initialisé à 0\n",
    "# si allw est sous forme de liste de couples [w1, w2], on doit la convertir en np.array pour la suite:\n",
    "allw = np.array(perceptron_biais.get_allw()) \n",
    "\n",
    "# Tracé de l'évolution des w:\n",
    "plt.figure()\n",
    "plt.plot(allw[:,0]) # première coordonnée du vecteur poids: w1\n",
    "plt.plot(allw[:,1]) # deuxième coordonnée du vecteur poids: w2\n",
    "plt.title('Evolution des w au cours des itérations du perceptron')\n",
    "plt.xlabel('iterations')\n",
    "plt.legend(['w1','w2'])\n",
    "\n",
    "# Sauvegarde de la figure obtenue (décommenter la ligne ci-dessous):\n",
    "# et créer un répertoire out/ dans le répertoire tme04\n",
    "# puis aller dans le répertoire `out` avec un navigateur de fichiers (ou par le terminal)\n",
    "# pour visualiser l'image obtenue par :\n",
    "\n",
    "# plt.savefig('out/cvg.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Remarque</b>: dans ce qui suit, on considére que la classe `ClassifierPerceptronBiais` se trouve dans ce notebook, pensez à corriger si vous avez déplacé votre classe dans `Classifiers.py` de votre librairie IADS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lien avec l'optimisation des fonctions de coût\n",
    "\n",
    "Après ces rappels de code, nous entrons maintenant dans le vif du sujet !\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "L'évolution des poids du perceptron correspond en réalité à l'optimisation de la fonction coût suivante (cela sera développé en cours):\n",
    "\n",
    "$$ \\mathcal C = \\sum_{i=1}^N [1- f(\\mathbf x_i) y_i]_+, \\qquad \\mbox{avec: } \n",
    "[\\alpha]_+ = \\left\\{\\begin{array}{ll}\n",
    "\\alpha & \\mbox{ si } \\alpha >0\\\\\n",
    "0 & \\mbox{ sinon }\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "Nous utilisons ici une version *stabilisée* du perceptron où les points ne sont bien classé que lorsque \n",
    "$f(\\mathbf x_i) y_i>1$\n",
    "\n",
    "Le perceptron est une simple descente de gradient.\n",
    "\n",
    "Deux questions se posent alors :\n",
    "1. Quelle est l'évolution de $\\mathcal C$ au cours des itérations ?\n",
    "1. Quel chemin de variations prennent les $w$ dans le cas 2D ?\n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Donner les instructions qui permettent de tracer l'évolution du coût $ \\mathcal C$ au cours des itérations lors de l'apprentissage précédent. Pour cela, vous utiliserez les valeurs de $w$ sauvegardées lors de l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toujours avec les mêmes données :\n",
    "X = data\n",
    "Y = label\n",
    "\n",
    "# on considère les poids de perceptron_biais généré dans une boite précédente:\n",
    "allw = np.array(perceptron_biais.get_allw()) \n",
    "\n",
    "# ------------------------  A COMPLETER :\n",
    "tabc = []\n",
    "for w in allw:\n",
    "    cout = 0\n",
    "    for i in range(len(X)):\n",
    "        score = np.dot(w, X[i])\n",
    "        if score * Y[i] < 1:\n",
    "            cout += max(0, 1 - score * Y[i])\n",
    "    tabc.append(cout)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tabc)\n",
    "plt.show()         \n",
    "# ------------------------ \n",
    "# Sauvegarde de la figure obtenue (décommenter la ligne ci-dessous):\n",
    "#plt.savefig('out/cost.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allw[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution des poids dans l'espace des paramètres\n",
    "\n",
    "Le code pour étudier l'évolution des poids dans l'espace des paramères est presque entièrement donné ci-dessous... Sauf une ligne critique !\n",
    "\n",
    "<b>Remarque</b>: il faut absolument comprendre la signification du code et de l'image produite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Evolution des poids dans l'espace des paramètres\n",
    "# le code est presque entièrement donné... Sauf une ligne critique\n",
    "# Il faut absolument comprendre la signification du code et de l'image produite\n",
    "\n",
    "# 1. Construction d'une grille de 'toutes' les valeurs possibles de w dans les bornes de allw\n",
    "mmax=allw.max(0)\n",
    "mmin=allw.min(0)\n",
    "x1grid,x2grid=np.meshgrid(np.linspace(mmin[0],mmax[0],30),np.linspace(mmin[1],mmax[1],30))\n",
    "grid=np.hstack((x1grid.reshape(x1grid.size,1),x2grid.reshape(x2grid.size,1)))\n",
    "\n",
    "# 2. Evaluation du cout pour toutes ces solutions potentielles\n",
    "\n",
    "##########\n",
    "# LIGNE A COMPLETER:\n",
    "# construction de res = calcul du cout du perceptron pour tous les couples\n",
    "# (w1,w2) définis dans grid\n",
    "\n",
    "# Comme plus haut mais version compacte\n",
    "res = np.array([np.sum([max(0, 1 - np.dot(w, X[i]) * Y[i]) for i in range(len(X))]) for w in grid])\n",
    "\n",
    "##########\n",
    "\n",
    "# remise en forme de res\n",
    "res=res.reshape(x1grid.shape) \n",
    "\n",
    "fig, ax = plt.subplots() # pour 1 et 2\n",
    "ax.set_xlabel('$w_1$')\n",
    "ax.set_ylabel('$w_2$')\n",
    "CS = ax.contour(x1grid,x2grid,res)\n",
    "ax.clabel(CS, inline=1, fontsize=10)\n",
    "\n",
    "# ajoute de la couleur: jaune = plus grande itération\n",
    "ax.scatter(allw[:,0], allw[:,1], c=np.arange(len(allw)))\n",
    "\n",
    "# Sauvegarde de la figure obtenue (décommenter la ligne ci-dessous):\n",
    "#plt.savefig(\"out/espace_param.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solution initiale $w=[0,0]$ correspond à un coût élevé. L'algorithme du perceptron fait évoluer les poids du modèle pour aller dans une zone de l'espace où le coût est moindre.\n",
    "\n",
    "**ATTENTION** à ne pas confondre l'espace de représentation des points (où les axes sont $X_1,X_2$) et l'espace de représentation des paramètres (ici, où chaque point correspond à un classifieur associé à un niveau de coût)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Croisée\n",
    "\n",
    "Dans le but d'évaluer un classifier, nous avons vu dans le TME 3 qu'il était important de posséder un ensemble de données de test, différent de l'ensemble d'apprentissage.\n",
    "\n",
    "Nous allons voir maintenant une méthode encore plus efficace pour bien évaluer un algorithme.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "La procédure de la <b>validation croisée</b> (ou <i>cross validation</i>) est au centre de la plupart des applications de machine learning: il est temps pour nous de travailler sur une implémentation.\n",
    "\n",
    "L'idée est de concevoir la fonction suivante:\n",
    "```\n",
    "Xapp,Yapp,Xtest,Ytest = crossval(X, Y, n_iterations, iteration)\n",
    "```\n",
    "- ```X, Y``` sont les données du dataset **mélangées aléatoirement**\n",
    "- ```n_iterations``` est le nombre d'ensembles de test au total.\n",
    "- ```iteration``` est l'itération concernée: on ne renvoit pas les mêmes données en fonction des itérations.\n",
    "\n",
    "Après séparation des indices en ```n_iterations``` groupes, isoler 1 groupe pour le test et les autres pour l'apprentissage.\n",
    "\n",
    "\n",
    "<b>Remarques:</b>\n",
    "- on fait l'hypothèse que le dataset (`X`, `Y`) garde toujours le même ordre entre 2 appels de `crossval` successif avec des valeurs d'itération différentes.\n",
    "- cette fonction ne doit pas mélanger les données du dataset fourni (qui doit être mélangé au préalable), elle sert juste à extraire de ce dataset 2 sous-datasets: un dataset d'apprentissage (`Xapp`, `Yapp`) et un dataset de test (`Xtest`, `Ytest`).\n",
    "- elle extrait les datasets demandés comme suit:\n",
    "    - le dataset de test pour l'itération $i$ contient les exemples du dataset $X$ dont les indices vont de $i\\frac{len(X)}{n}$ à  $(i+1)\\frac{len(X)}{n}-1$ (avec $n$ le nombre d'itérations `n_iterations` fixé).\n",
    "    - le dataset d'apprentissage pour l'itération $i$ contient les exemples du dataset $X$ contient les exemples qui ne sont pas dans le dataset de test.\n",
    "\n",
    "</div>    \n",
    "    \n",
    "**Note** Pour mélanger les données au départ, avant le premier appel de `crossval`, vous pouvez utiliser les commandes suivantes:\n",
    "```\n",
    "index = np.random.permutation(len(X)) # mélange des index\n",
    "Xm = X[index]\n",
    "Ym = Y[index]\n",
    "\n",
    "# check: malgré le mélange, les données doivent être les mêmes\n",
    "plt.figure()\n",
    "plt.scatter(Xm[Ym==1,0], Xm[Ym==1,1], c='b')\n",
    "plt.scatter(Xm[Ym==-1,0], Xm[Ym==-1,1], c='r')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Donner la définition de la fonction `crossval` telle qu'elle est décrite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(X, Y, n_iterations, iteration):\n",
    "\n",
    "    taille_test = len(X) // n_iterations\n",
    "    i_test = slice(iteration * taille_test, (iteration + 1) * taille_test)\n",
    "    i_train = np.concatenate([np.arange(0, iteration * taille_test),\n",
    "                                np.arange((iteration + 1) * taille_test, len(X))])\n",
    "    Xtest = X[i_test]\n",
    "    Ytest = Y[i_test]\n",
    "    Xapp = X[i_train]\n",
    "    Yapp = Y[i_train]\n",
    "    \n",
    "    return Xapp, Yapp, Xtest, Ytest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarder l'exemple d'utilisation suivant, sur un dataset jouet, pour comprendre comment sont pris les exemples à chaque appel différent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour vérifier que le traitement est bien réalisé et que tout marche bien \n",
    "# en particulier (très important !) que le lien entre descriptions X et classes Y n'est pas perdu,\n",
    "# on peut regarder ce qui se passe si X et Y sont les mêmes:\n",
    "\n",
    "N = 24  # Nombre d'exemples dans le dataset\n",
    "Xjouet = np.array([i for i in range(0,N)])   \n",
    "Yjouet = Xjouet  # Yjouet est identique à Xjouet\n",
    "\n",
    "niter = 4\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval(Xjouet, Yjouet, niter, i)\n",
    "    print(\"========== ITERATION : \",i,\" ==========\")\n",
    "    print(\" Xapp=\", Xapp.T,\"\\n\",\"Yapp=\", Yapp,\"\\n\",\"Xtest=\",Xtest.T,\"\\n\",\"Ytest=\", Ytest)\n",
    "    \n",
    "    \n",
    "print(\"\\n*********************\\nEt on peut rappeler la fonction avec 0 par exemple: \")    \n",
    "Xapp,Yapp,Xtest,Ytest = crossval(Xjouet, Yjouet, niter, 0)\n",
    "print(\" Xapp=\", Xapp.T,\"\\n\",\"Yapp=\", Yapp,\"\\n\",\"Xtest=\",Xtest.T,\"\\n\",\"Ytest=\", Ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> En fait, pour faire les choses correctement, il faut que la séparation des ensembles train/test respecte la distribution des classes dans le dataset de départ. Ecrire la fonction `crossval_strat` qui effectue la même chose que la fonction précédente mais en respectant la distribution des classes. La solution passe par un découpage qui s'effectue par classe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code de la validation croisée (version qui respecte la distribution des classes)\n",
    "\n",
    "def crossval_strat(X, Y, n_iterations, iteration):\n",
    "        # Séparation par classe\n",
    "    Xp = {}\n",
    "    Yp = {}\n",
    "    for i in range(len(X)):\n",
    "        if Y[i] not in Xp:\n",
    "            Xp[Y[i]] = []\n",
    "            Yp[Y[i]] = []\n",
    "        Xp[Y[i]].append(X[i])\n",
    "        Yp[Y[i]].append(Y[i])\n",
    "    \n",
    "    # Calculer le nombre d'exemples pour chaque ensemble de test\n",
    "    n_test = {}\n",
    "    for k, v in Xp.items():\n",
    "        n_test[k] = int(len(v) / n_iterations)\n",
    "    \n",
    "    # Extraire les exemples pour l'ensemble de test courant\n",
    "    Xtest = []\n",
    "    Ytest = []\n",
    "    for k, v in Xp.items():\n",
    "        start = iteration * n_test[k]\n",
    "        end = start + n_test[k]\n",
    "        Xtest += v[start:end]\n",
    "        Ytest += Yp[k][start:end]\n",
    "        \n",
    "    # Extraire les exemples pour l'ensemble d'apprentissage\n",
    "    Xapp = []\n",
    "    Yapp = []\n",
    "    for k, v in Xp.items():\n",
    "        Xapp += v[:iteration*n_test[k]] + v[(iteration+1)*n_test[k]:]\n",
    "        Yapp += Yp[k][:iteration*n_test[k]] + Yp[k][(iteration+1)*n_test[k]:]\n",
    "    \n",
    "    # Convertir en numpy arrays\n",
    "    Xapp = np.array(Xapp)\n",
    "    Yapp = np.array(Yapp)\n",
    "    Xtest = np.array(Xtest)\n",
    "    Ytest = np.array(Ytest)\n",
    "   \n",
    "    return Xapp, Yapp, Xtest, Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation avec un dataset jouet (1 Dimension)\n",
    "N = 24  # Nombre d'exemples dans le dataset\n",
    "#Xtoy = np.arange(N).reshape(N,1)\n",
    "Xtoy = np.array([i for i in range(0,N)])   \n",
    "Ytoy = np.array([-1]*(N//2) + [1]*(N//2))\n",
    "#index = np.random.permutation(len(Xtoy)) # mélange des index\n",
    "#XtoyMelange = Xtoy[index]\n",
    "#YtoyMelange = Ytoy[index]\n",
    "\n",
    "niter = 3\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval_strat(Xtoy, Ytoy, niter, i)\n",
    "    print(\"========== ITERATION : \",i,\" ==========\")\n",
    "    print(\" Xapp=\", Xapp.T,\"\\n\",\"Yapp=\", Yapp,\"\\n\",\"Xtest=\",Xtest.T,\"\\n\",\"Ytest=\", Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque**: il est important, avant d'utiliser `crossval` ou `crossval_strat` de mélanger le dataset. Ce mélange aléatoire doit être fait une seule fois avant le premier appel de la fonction (et jamais entre 2 appels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Exemple d'utilisation avec un dataset jouet (1 Dimension)\n",
    "N = 24  # Nombre d'exemples dans le dataset\n",
    "Xtoy = np.array([i for i in range(0,N)])   \n",
    "Ytoy = np.array([-1]*(N//2) + [1]*(N//2))\n",
    "index = np.random.permutation(len(Xtoy)) # mélange des index\n",
    "XtoyMelange = Xtoy[index]\n",
    "YtoyMelange = Ytoy[index]\n",
    "\n",
    "niter = 3\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval_strat(XtoyMelange, YtoyMelange, niter, i)\n",
    "    print(\"========== ITERATION : \",i,\" ==========\")\n",
    "    print(\" Xapp=\", Xapp.T,\"\\n\",\"Yapp=\", Yapp,\"\\n\",\"Xtest=\",Xtest.T,\"\\n\",\"Ytest=\", Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests de la procédure de validation croisée \n",
    "\n",
    "Sur des données réelles et sur des données jouets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "# test sur les données jouet X, Y supposées pré-existantes\n",
    "\n",
    "index = np.random.permutation(len(X)) # mélange des index\n",
    "Xm = X[index]\n",
    "Ym = Y[index]\n",
    "niter = 10\n",
    "perf = []\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = 2\n",
    "eps = 1e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "for i in range(niter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval(Xm, Ym, niter, i)\n",
    "    perceptron4 = ClassifierPerceptronBiais(dim, eps, poids_0)\n",
    "    perceptron4.train(Xapp, Yapp)\n",
    "    perf.append(perceptron4.accuracy(Xtest, Ytest))\n",
    "    \n",
    "print(\"Perf \",perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Tester la validation croisée sur les données USPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sur les données USPS\n",
    "import pickle as pkl\n",
    "\n",
    "data = pkl.load(open('ressources/usps.pkl', 'rb'))\n",
    "Xu = np.array(data['X_train'], dtype=float) # conversion de type pour une meilleure compatibilité\n",
    "Yu = np.array(data['Y_train'], dtype=float)\n",
    "\n",
    "# Création d'un sous groupe de données\n",
    "c1 = 4  # ---> sera associée au label +1  \n",
    "c2 = 6  # ---> sera associée au label -1\n",
    "X12 = Xu[(Yu==c1) | (Yu==c2)]\n",
    "Y12 = np.where(Yu[(Yu==c1) | (Yu==c2)]==c1, 1, -1)\n",
    "\n",
    "np.random.seed(42)   # on prend 42 comme graine\n",
    "\n",
    "# Paramètres pour le perceptron:\n",
    "dim = X12.shape[1]   # la dimension est donnée par le nombre de colonnes de X12\n",
    "eps = 1e-3    # learning rate\n",
    "poids_0 = True   # valeur initiale des poids à 0\n",
    "\n",
    "# Nombre d'itérations voulues pour la validation croisée:\n",
    "nb_iter = 10\n",
    "# Liste pour stocker les taux de bonne classification à chaque itération\n",
    "perf = []\n",
    "\n",
    "# ######################## A COMPLETER CI-DESSOUS\n",
    "# 1) mélanger des exemples\n",
    "index = np.random.permutation(len(X12)) # mélange des index\n",
    "Xm = X12[index]\n",
    "Ym = Y12[index]\n",
    "\n",
    "# 2) réaliser une validation croisée complète \n",
    "for i in range(nb_iter):\n",
    "    Xapp,Yapp,Xtest,Ytest = crossval(Xm, Ym, nb_iter, i)\n",
    "    perceptron5 = ClassifierPerceptronBiais(dim, eps, poids_0)\n",
    "    perceptron5.train(Xapp, Yapp)\n",
    "    bc = perceptron5.accuracy(Xtest, Ytest)\n",
    "    perf.append(bc)\n",
    "    print(\"Iteration \" + str(i) + \" : taille base app.= \" + str(len(Xapp)) + \" taille base test= \" + str(len(Xtest)) + \" Taux de bonne classif: \" + str(bc))\n",
    "\n",
    "# ------------------------ \n",
    "    \n",
    "print(\"Perf obtenues : \",perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Pour évaluer un classifieur, on regarde la moyenne et l'écart type de son taux de bonne classification lors d'une validation croisée.\n",
    "\n",
    "Ecrire la fonction `analyse_perfs` qui prend en argument une liste de nombres réels (non vide) et renvoie le tuple constitué de la moyenne et de l'écart type de ces nombres.\n",
    "\n",
    "**Remarque**: l'écart type donne une information sur la \"robustesse\" du modèle. Plus il est grand, est plus cela signifie que la performance du classifieur dépend du jeu d'apprentissage qui a servi à le construire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ A COMPLETER\n",
    "def analyse_perfs(L):\n",
    "    \"\"\" L : liste de nombres réels non vide\n",
    "        rend le tuple (moyenne, écart-type)\n",
    "    \"\"\"\n",
    "    return (sum(L)/len(L), np.std(L))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sur les résultats obtenus dans la boîte précédemment:\n",
    "analyse_perfs(perf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
